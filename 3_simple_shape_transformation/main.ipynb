{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017b9741-ff62-47ca-af93-74bd68cbfbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "pytorch  : 1.9.0\n",
      "open3d   : 0.13.0\n",
      "pytorch3d: 0.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import pytorch3d as p3d\n",
    "from pytorch3d.transforms.so3 import *\n",
    "\n",
    "print('pytorch  :', torch.__version__)\n",
    "print('open3d   :', o3d.__version__)\n",
    "print('pytorch3d:', p3d.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8668e17-a654-415c-9b46-3b6537d32bdf",
   "metadata": {},
   "source": [
    "### Helper function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cab2b3-f72e-4a6d-b5ea-d7b8b1a35400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_two_pointcloud(source, target):\n",
    "    source.paint_uniform_color([1, 0.706, 0])\n",
    "    target.paint_uniform_color([0, 0.651, 0.929])\n",
    "    o3d.visualization.draw_geometries([source, target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c5799-c20b-41e8-8c2b-f422f5efd309",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6af397-4cc0-4605-95f3-634e7ca64fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original shape (ref: http://graphics.stanford.edu/data/3Dscanrep/) \n",
    "bunny_original = o3d.io.read_point_cloud('bun_zipper_res2.ply')\n",
    "bunny_original_xyz = torch.Tensor(np.asarray(bunny_original.points))\n",
    "o3d.visualization.draw_geometries([bunny_original])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac75aa6-6dbf-4268-b8fa-e662b51e3862",
   "metadata": {},
   "source": [
    "### Random transformation to the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "146c8071-1611-4f5d-9901-57b8a8ed2896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random transform:\n",
      " [[ 0.15794468  0.98420227 -0.07999662  0.1610954 ]\n",
      " [ 0.15273811  0.0556879   0.98669648  0.13217635]\n",
      " [ 0.97556376 -0.16806208 -0.14152956  0.11073001]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# apply the random rotation \n",
    "random_rot = p3d.transforms.random_rotation().squeeze().numpy()\n",
    "random_trans = 0.2*torch.rand(3).numpy()\n",
    "random_tf = np.eye(4,4)\n",
    "random_tf[:3, :3] = random_rot\n",
    "random_tf[:3, -1] = random_trans\n",
    "print('Random transform:\\n', random_tf)\n",
    "\n",
    "bunny_transformed = o3d.io.read_point_cloud('bun_zipper_res2.ply')\n",
    "bunny_transformed.transform(random_tf) # in-place transformation \n",
    "\n",
    "# add noise \n",
    "bunny_transformed_xyz = torch.Tensor(np.asarray(bunny_transformed.points))\n",
    "bunny_transformed_xyz = bunny_transformed_xyz + 0.01*torch.rand(bunny_transformed_xyz.shape)\n",
    "\n",
    "# draw \n",
    "bunny_transformed.points = o3d.utility.Vector3dVector(bunny_transformed_xyz.detach().numpy())\n",
    "draw_two_pointcloud(bunny_original, bunny_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d15e49-3e01-4281-957b-549888888aa4",
   "metadata": {},
   "source": [
    "### Define the model \n",
    "- to learn the related transformation between the original and the transformed clouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea87194a-5487-4e88-9022-aa606422b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealiveTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RealiveTransform, self).__init__()\n",
    "        self.rot_part1 = nn.Parameter(torch.rand(3, 3)) \n",
    "        self.rot_part2 = nn.Parameter(torch.rand(3, 1024)) \n",
    "        self.rot_part3 = nn.Parameter(torch.rand(1024, 3)) \n",
    "        \n",
    "        self.trans_part1 = nn.Parameter(torch.rand(3, 3))\n",
    "        self.trans_part2 = nn.Parameter(torch.rand(3, 1024))\n",
    "        self.trans_part3 = nn.Parameter(torch.rand(1024, 1))\n",
    "         \n",
    "    def forward(self, x):\n",
    "        # x: n x 3 \n",
    "        # y: n x 3 \n",
    "        rotmat = torch.mm(torch.mm(self.rot_part1, self.rot_part2), self.rot_part3)\n",
    "        transvec = torch.mm(torch.mm(self.trans_part1, self.trans_part2), self.trans_part3)\n",
    "        y = (torch.mm(rotmat, x.t()) + transvec).t()\n",
    "        return y\n",
    "    \n",
    "    def get_tf(self):\n",
    "        rotmat = torch.mm(torch.mm(self.rot_part1, self.rot_part2), self.rot_part3)\n",
    "        transvec = torch.mm(torch.mm(self.trans_part1, self.trans_part2), self.trans_part3)\n",
    "        return {'R': rotmat, 't': transvec}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ceb601-1b32-4634-9ede-b4713b5e8845",
   "metadata": {},
   "source": [
    "### Initial verification of the estimated transformation before the optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30dea77e-c37f-4253-b20d-395c0afcc1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated R:\n",
      " tensor([[655.1071, 663.0014, 652.4586],\n",
      "        [356.2054, 359.5293, 356.0751],\n",
      "        [604.0523, 611.2412, 602.0819]], grad_fn=<MmBackward>)\n",
      "Estimated t:\n",
      " tensor([[281.7417, 476.4532, 647.5089]], grad_fn=<TBackward>)\n"
     ]
    }
   ],
   "source": [
    "realive_transform = RealiveTransform()\n",
    "bunny_registered_xyz = realive_transform(bunny_transformed_xyz)\n",
    "\n",
    "estimated_relative_tf = realive_transform.get_tf()\n",
    "print('Estimated R:\\n', estimated_relative_tf['R'])\n",
    "print('Estimated t:\\n', estimated_relative_tf['t'].t())\n",
    "\n",
    "bunny_registered = o3d.geometry.PointCloud()\n",
    "bunny_registered.points = o3d.utility.Vector3dVector(bunny_registered_xyz.detach().numpy())\n",
    "draw_two_pointcloud(bunny_original, bunny_registered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85ede2-d332-4812-bf16-dd40b2c450b7",
   "metadata": {},
   "source": [
    "### Fit the data (i.e., learning of the relative transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b27f044b-56d6-4c58-bbc8-e525e7ad8367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 17754754.000000\n",
      "loss: 184.976654\n",
      "loss:  63.152931\n",
      "loss:  63.836708\n",
      "loss:  60.856045\n",
      "True R     :\n",
      " [[ 0.15794468  0.98420227 -0.07999662]\n",
      " [ 0.15273811  0.0556879   0.9866965 ]\n",
      " [ 0.97556376 -0.16806208 -0.14152956]]\n",
      "True t     :\n",
      " [0.1610954  0.13217635 0.11073001]\n",
      "Estimated R:\n",
      " tensor([[ 0.1535,  0.1491,  0.9681],\n",
      "        [ 0.9746,  0.0546, -0.1683],\n",
      "        [-0.0832,  0.9685, -0.1402]], grad_fn=<MmBackward>)\n",
      "Estimated t:\n",
      " tensor([[-0.1577, -0.1490, -0.1023]], grad_fn=<TBackward>)\n"
     ]
    }
   ],
   "source": [
    "# realive_transform = realive_transform.cpu()\n",
    "# bunny_original_xyz = bunny_original_xyz.cpu()\n",
    "\n",
    "# optimizer \n",
    "optimizer = optim.Adam(realive_transform.parameters(), lr=0.01)\n",
    "\n",
    "# run optimization \n",
    "for i in range(50000):\n",
    "    optimizer.zero_grad()\n",
    "    bunny_registered_xyz_est = realive_transform(bunny_transformed_xyz)\n",
    "    \n",
    "    # assumption: point correspondonces are known (so simply applying same-row l1(or l2) subtraction for the loss)\n",
    "    use_l1loss = True\n",
    "    if use_l1loss:\n",
    "        loss = torch.abs(bunny_registered_xyz_est - bunny_original_xyz).sum(dim=1).sum() # L1 \n",
    "    else:\n",
    "        loss = torch.square(torch.abs(pts_est - pts_orig).sum(dim=1)).sum() # L2\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        loss, current = loss.item(), i * len(bunny_transformed_xyz)\n",
    "        print(f\"loss: {loss:>10f}\")\n",
    "\n",
    "# result \n",
    "estimated_relative_tf = realive_transform.get_tf()\n",
    "print('True R     :\\n', random_rot)\n",
    "print('True t     :\\n', random_trans)\n",
    "print('Estimated R:\\n', estimated_relative_tf['R'])\n",
    "print('Estimated t:\\n', estimated_relative_tf['t'].t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac3586-29e4-4572-ab59-829ad9ffb41e",
   "metadata": {},
   "source": [
    "### Verification of the estimated results (i.e., estimated registered point cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d108433-ac59-412e-b35a-cd489b778879",
   "metadata": {},
   "outputs": [],
   "source": [
    "bunny_registered_xyz_est = realive_transform(bunny_transformed_xyz)\n",
    "bunny_registered_xyz_est = bunny_registered_xyz_est.detach().cpu().numpy()\n",
    "\n",
    "bunny_registered_est = o3d.geometry.PointCloud()\n",
    "bunny_registered_est.points = o3d.utility.Vector3dVector(bunny_registered_xyz_est)\n",
    "draw_two_pointcloud(bunny_original, bunny_registered_est)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
